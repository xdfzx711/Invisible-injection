#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Twitteræ•°æ®æ”¶é›†å™¨
ä½¿ç”¨Twitter API v2å’Œsnscrapeæ”¶é›†æ¨æ–‡æ•°æ®
"""

import json
import time
import re
from pathlib import Path
from typing import Dict, Any, List
from datetime import datetime

# å°è¯•å¯¼å…¥snscrape
try:
    import snscrape.modules.twitter as sntwitter
    import snscrape
    SNSCRAPE_AVAILABLE = True
    snscrape_version = getattr(snscrape, '__version__', 'unknown')
except ImportError:
    SNSCRAPE_AVAILABLE = False
    snscrape_version = None

# å°è¯•å¯¼å…¥tweepy
try:
    import tweepy
    TWEEPY_AVAILABLE = True
except ImportError:
    TWEEPY_AVAILABLE = False

from data_collection.base_collector import BaseCollector


class TwitterCollector(BaseCollector):
    """Twitteræ•°æ®æ”¶é›†å™¨ - æ”¯æŒå®˜æ–¹APIå’Œsnscrape"""
    
    def __init__(self):
        super().__init__('twitter')
        
        print(f"ğŸ“¦ snscrapeç‰ˆæœ¬: {snscrape_version if SNSCRAPE_AVAILABLE else 'not installed'}")
        
        # é…ç½®Fileè·¯å¾„
        self.config_file = self.get_config_path('twitter_config.json')
        
        # å¦‚æœé…ç½®ä¸åœ¨æ–°ä½ç½®ï¼Œå°è¯•ä»æ—§ä½ç½®è¯»å–
        if not self.config_file.exists():
            old_config = self.path_manager.get_project_root() / "twitter_collect" / "twitter_config.json"
            if old_config.exists():
                self.config_file = old_config
                self.logger.info(f"Using config from old location: {old_config}")
        
        # Twitter APIå¯¹è±¡ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self.client = None
        self.config = None
        self.data_source = "hybrid"  # hybrid, snscrape, api
        self.api_available = False
        self.snscrape_available = SNSCRAPE_AVAILABLE
    
    def validate_config(self) -> bool:
        """éªŒè¯é…ç½®"""
        if not self.config_file.exists():
            self.logger.warning(f"Config file not found: {self.config_file}")
            print(f"\nWarning: æœªæ‰¾åˆ°Twitteré…ç½®File")
            print(f"å°†å°è¯•ä½¿ç”¨snscrapeæ¨¡å¼ï¼ˆä¸éœ€è¦APIå¯†é’¥ï¼‰")
            print(f"\nå¦‚éœ€ä½¿ç”¨å®˜æ–¹APIï¼Œè¯·åˆ›å»ºé…ç½®File:")
            print(f"  {self.config_file}")
            print("\nç¤ºä¾‹å†…å®¹:")
            print(json.dumps({
                "bearer_token": "your_bearer_token",
                "api_key": "your_api_key",
                "api_secret": "your_api_secret",
                "access_token": "your_access_token",
                "access_token_secret": "your_access_token_secret"
            }, indent=2))
            return SNSCRAPE_AVAILABLE
        
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                self.config = json.load(f)
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to validate config: {e}")
            return SNSCRAPE_AVAILABLE
    
    def _setup_api(self) -> bool:
        """è®¾ç½®Twitter APIå®¢æˆ·ç«¯"""
        if not self.config:
            self.logger.info("No API config, will use snscrape if available")
            return SNSCRAPE_AVAILABLE
        
        if not TWEEPY_AVAILABLE:
            self.logger.warning("tweepy not installed, can only use snscrape")
            return SNSCRAPE_AVAILABLE
        
        try:
            self.client = tweepy.Client(
                bearer_token=self.config.get('bearer_token'),
                consumer_key=self.config.get('api_key'),
                consumer_secret=self.config.get('api_secret'),
                access_token=self.config.get('access_token'),
                access_token_secret=self.config.get('access_token_secret'),
                wait_on_rate_limit=True
            )
            self.api_available = True
            print("âœ… Twitterå®˜æ–¹APIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            self.logger.info("Twitter API client initialized")
            return True
            
        except Exception as e:
            self.logger.warning(f"Failed to setup Twitter API: {e}")
            print(f"âš ï¸ Twitterå®˜æ–¹APIåˆå§‹åŒ–Failed: {e}")
            print("ğŸ’¡ å°†ä½¿ç”¨snscrapeæ¨¡å¼")
            return SNSCRAPE_AVAILABLE
    
    def collect(self) -> Dict[str, Any]:
        """ä¸»æ”¶é›†æ–¹æ³•"""
        self.start_collection()
        
        try:
            # éªŒè¯é…ç½®
            if not self.validate_config():
                return {
                    'success': False,
                    'message': 'No valid data source available',
                    'stats': self.get_stats()
                }
            
            # è®¾ç½®API
            self._setup_api()
            
            # æ˜¾ç¤ºå¯ç”¨çš„æ•°æ®æº
            self._print_data_source_info()
            
            print("\nTwitteræ•°æ®æ”¶é›†")
            print("-" * 70)
            
            # è·å–ç”¨æˆ·è¾“å…¥
            print("\nè¯·è¾“å…¥è¦æœç´¢çš„å…³é”®è¯ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰")
            print("ç¤ºä¾‹: unicode,security,python")
            user_input = input("\nå…³é”®è¯: ").strip()
            
            if not user_input:
                print("Error: æœªè¾“å…¥å…³é”®è¯")
                return {
                    'success': False,
                    'message': 'No keywords provided',
                    'stats': self.get_stats()
                }
            
            keywords = [k.strip() for k in user_input.split(',')]
            
            # è·å–æ•°é‡
            print("\nè¯·è¾“å…¥æ¯ä¸ªå…³é”®è¯è¦æ”¶é›†çš„æ¨æ–‡æ•°é‡")
            print("ï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤: 100ï¼‰")
            limit_input = input("\næ¨æ–‡æ•°é‡: ").strip()
            
            if not limit_input:
                limit = 100
            else:
                try:
                    limit = int(limit_input)
                except ValueError:
                    print("æ— æ•ˆæ•°é‡ï¼Œä½¿ç”¨é»˜è®¤: 100")
                    limit = 100
            
            # æ”¶é›†æ•°æ®
            print(f"\nå¼€å§‹æ”¶é›† {len(keywords)} ä¸ªå…³é”®è¯çš„æ¨æ–‡...")
            print(f"Output directory: {self.output_dir}")
            print("-" * 70)
            
            for keyword in keywords:
                try:
                    print(f"\næ­£åœ¨æ”¶é›†: {keyword}")
                    # æ”¶é›†æ•°æ®
                    data = self._search_tweets(keyword, max_results=limit)
                    
                    # ä¿å­˜æ•°æ®
                    if data:
                        # ç”Ÿæˆå®‰å…¨çš„Fileå
                        safe_filename = keyword.replace(' ', '_').replace('#', '').replace('@', '')[:50]
                        filename = f"{safe_filename}_tweets.json"
                        self._save_data(data, filename)
                        self.increment_success()
                        print(f"  æˆåŠŸå¹¶has beenä¿å­˜")
                    else:
                        self.increment_failure()
                        print(f"  Failed: æœªæ”¶é›†åˆ°æ•°æ®")
                except Exception as e:
                    self.logger.error(f"Failed to collect tweets for '{keyword}': {e}")
                    self.increment_failure()
                    print(f"  Failed: {e}")
            
            self.end_collection()
            self.log_summary()
            
            # ç»Ÿè®¡æ”¶é›†çš„File
            file_count = len(list(self.output_dir.glob('*.json')))
            
            return {
                'success': True,
                'file_count': file_count,
                'output_dir': str(self.output_dir),
                'stats': self.get_stats(),
                'message': f'Successfully collected {self.stats["successful_items"]} keywords'
            }
            
        except KeyboardInterrupt:
            print("\n\nç”¨æˆ·ä¸­æ–­æ”¶é›†")
            self.end_collection()
            return {
                'success': False,
                'message': 'Collection interrupted',
                'file_count': len(list(self.output_dir.glob('*.json'))),
                'stats': self.get_stats()
            }
        except Exception as e:
            self.logger.error(f"Twitter collection failed: {e}", exc_info=True)
            self.end_collection()
            return {
                'success': False,
                'message': f'Collection failed: {e}',
                'stats': self.get_stats()
            }
    
    def _print_data_source_info(self):
        """æ˜¾ç¤ºæ•°æ®æºä¿¡æ¯"""
        print("ğŸ”§ æ•°æ®æ”¶é›†å™¨é…ç½®:")
        print(f"   ğŸ“Š æ•°æ®æºæ¨¡å¼: {self.data_source}")
        print(f"   ğŸ”‘ å®˜æ–¹API: {'âœ… å¯ç”¨' if self.api_available else 'âŒ ä¸å¯ç”¨'}")
        print(f"   ğŸ•·ï¸ snscrape: {'âœ… å¯ç”¨' if self.snscrape_available else 'âŒ ä¸å¯ç”¨'}")
        
        if self.data_source == "hybrid":
            print("ğŸ’¡ æ··åˆæ¨¡å¼ï¼šä¼˜å…ˆsnscrapeï¼Œå¤‡ç”¨å®˜æ–¹API")
        elif self.data_source == "snscrape":
            print("ğŸ’¡ snscrapeæ¨¡å¼ï¼šæ— éœ€APIå¯†é’¥ï¼Œæ— é€Ÿç‡é™åˆ¶")
        elif self.data_source == "api":
            print("ğŸ’¡ å®˜æ–¹APIæ¨¡å¼ï¼šéœ€è¦è®¤è¯ï¼Œæœ‰é€Ÿç‡é™åˆ¶")
        
        print("-" * 70)
    
    def _search_tweets(self, query: str, max_results: int = 100) -> Dict[str, Any]:
        """æœç´¢æ¨æ–‡ - æ”¯æŒå¤šç§æ•°æ®æº"""
        print(f"ğŸ” æœç´¢æ¨æ–‡: '{query}'")
        print(f"ğŸ“Š ç›®æ ‡æ•°é‡: {max_results} entriesæ¨æ–‡")
        
        # æ ¹æ®æ•°æ®æºé€‰æ‹©æœç´¢æ–¹æ³•
        if self.data_source == "snscrape":
            return self._search_tweets_snscrape(query, max_results)
        elif self.data_source == "api":
            return self._search_tweets_api(query, max_results)
        else:  # hybrid
            return self._search_tweets_hybrid(query, max_results)
    
    def _search_tweets_hybrid(self, query: str, max_results: int) -> Dict[str, Any]:
        """æ··åˆæ¨¡å¼æœç´¢ - æ™ºèƒ½å›é€€ç­–ç•¥"""
        print("ğŸ”„ ä½¿ç”¨æ··åˆæ¨¡å¼æœç´¢")
        
        # ä¼˜å…ˆä½¿ç”¨snscrape
        if self.snscrape_available:
            print("ğŸ•·ï¸ ç¬¬ä¸€æ­¥ï¼šå°è¯•snscrape...")
            result = self._search_tweets_snscrape(query, max_results)
            if result and result.get('tweets'):
                print("âœ… snscrapeæœç´¢æˆåŠŸ")
                return result
            else:
                print("âš ï¸ snscrapeæœªæ‰¾åˆ°ç»“æœæˆ–Failed")
        
        # å›é€€åˆ°å®˜æ–¹API
        if self.api_available:
            print("ğŸ”„ ç¬¬äºŒæ­¥ï¼šå›é€€åˆ°å®˜æ–¹API...")
            try:
                result = self._search_tweets_api(query, max_results)
                if result and result.get('tweets'):
                    print("âœ… å®˜æ–¹APIæœç´¢æˆåŠŸ")
                    return result
                else:
                    print("âš ï¸ å®˜æ–¹APIæœªæ‰¾åˆ°ç»“æœ")
            except Exception as e:
                print(f"âš ï¸ å®˜æ–¹APIFailed: {e}")
        
        # æ‰€æœ‰æ–¹æ³•éƒ½Failed
        print("âŒ æ‰€æœ‰æ•°æ®æºéƒ½Failed")
        return None
    
    def _search_tweets_snscrape(self, query: str, max_results: int) -> Dict[str, Any]:
        """ä½¿ç”¨snscrapeæœç´¢æ¨æ–‡"""
        if not self.snscrape_available:
            print("âŒ snscrapeä¸å¯ç”¨")
            return None
        
        print(f"ğŸ•·ï¸ ä½¿ç”¨snscrapeæœç´¢æ¨æ–‡: '{query}'")
        tweets_data = []
        
        try:
            scraper = sntwitter.TwitterSearchScraper(query)
            
            tweet_count = 0
            for i, tweet in enumerate(scraper.get_items()):
                if i >= max_results:
                    break
                
                try:
                    # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
                    processed_tweet = {
                        "id": str(tweet.id),
                        "text": tweet.content or "",
                        "author_id": str(tweet.user.id) if tweet.user else "",
                        "author_username": tweet.user.username if tweet.user else "",
                        "author_name": tweet.user.displayname if tweet.user else "",
                        "created_at": tweet.date.isoformat() if tweet.date else "",
                        "lang": tweet.lang or "",
                        "public_metrics": {
                            "retweet_count": getattr(tweet, 'retweetCount', 0) or 0,
                            "like_count": getattr(tweet, 'likeCount', 0) or 0,
                            "reply_count": getattr(tweet, 'replyCount', 0) or 0,
                            "quote_count": getattr(tweet, 'quoteCount', 0) or 0
                        },
                        "url": tweet.url or "",
                        "source": "snscrape"
                    }
                    tweets_data.append(processed_tweet)
                    tweet_count += 1
                    
                    # è¿›åº¦æ˜¾ç¤º
                    if tweet_count % 10 == 0:
                        print(f"ğŸ“„ has beenè·å– {tweet_count} entriesæ¨æ–‡...")
                    
                    # æ·»åŠ å°å»¶è¿Ÿ
                    if tweet_count % 20 == 0:
                        time.sleep(0.5)
                
                except Exception as tweet_error:
                    self.logger.warning(f"Failed to process tweet: {tweet_error}")
                    continue
            
            if len(tweets_data) > 0:
                print(f"âœ… snscrapeæœç´¢Completedï¼Œè·å– {len(tweets_data)} entriesæ¨æ–‡")
                return {
                    "collection_info": {
                        "query": query,
                        "timestamp": datetime.now().isoformat(),
                        "tweets_count": len(tweets_data),
                        "data_source": "snscrape"
                    },
                    "tweets": tweets_data
                }
            else:
                print("âš ï¸ snscrapeæœªè·å–åˆ°ä»»ä½•æ¨æ–‡")
                return None
        
        except Exception as e:
            self.logger.error(f"snscrape search failed: {e}")
            print(f"âŒ snscrapeæœç´¢Failed: {e}")
            return None
    
    def _search_tweets_api(self, query: str, max_results: int) -> Dict[str, Any]:
        """ä½¿ç”¨å®˜æ–¹APIæœç´¢æ¨æ–‡"""
        if not self.api_available:
            print("âŒ å®˜æ–¹APIä¸å¯ç”¨")
            return None
        
        print(f"ğŸ”‘ ä½¿ç”¨å®˜æ–¹APIæœç´¢æ¨æ–‡: '{query}'")
        
        try:
            response = self.client.search_recent_tweets(
                query=query,
                max_results=min(max_results, 100),  # APIé™åˆ¶
                tweet_fields=['created_at', 'author_id', 'lang', 'public_metrics', 'source'],
                user_fields=['username', 'name', 'verified']
            )
            
            if not response.data:
                print("âš ï¸ å®˜æ–¹APIæœªæ‰¾åˆ°æ¨æ–‡")
                return None
            
            tweets_data = []
            for tweet in response.data:
                tweet_info = {
                    "id": str(tweet.id),
                    "text": tweet.text,
                    "author_id": str(tweet.author_id) if hasattr(tweet, 'author_id') else "",
                    "created_at": tweet.created_at.isoformat() if hasattr(tweet, 'created_at') else "",
                    "lang": tweet.lang if hasattr(tweet, 'lang') else "",
                    "public_metrics": tweet.public_metrics if hasattr(tweet, 'public_metrics') else {},
                    "source": "twitter_api"
                }
                tweets_data.append(tweet_info)
            
            print(f"âœ… å®˜æ–¹APIæœç´¢Completedï¼Œè·å– {len(tweets_data)} entriesæ¨æ–‡")
            return {
                "collection_info": {
                    "query": query,
                    "timestamp": datetime.now().isoformat(),
                    "tweets_count": len(tweets_data),
                    "data_source": "twitter_api"
                },
                "tweets": tweets_data
            }
        
        except Exception as e:
            self.logger.error(f"API search failed: {e}")
            print(f"âŒ å®˜æ–¹APIæœç´¢Failed: {e}")
            return None
    
    def _save_data(self, data: Dict[str, Any], filename: str):
        """ä¿å­˜æ•°æ®åˆ°JSONFileï¼Œæ”¯æŒåˆå¹¶å’Œå»é‡"""
        filepath = self.output_dir / filename
        
        try:
            # CheckFileæ˜¯å¦has beenexists
            if filepath.exists():
                # åŠ è½½ç°æœ‰æ•°æ®
                with open(filepath, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
                
                # åˆå¹¶æ¨æ–‡æ•°æ®ï¼Œæ ¹æ®IDå»é‡
                existing_tweet_ids = {t['id'] for t in existing_data.get('tweets', [])}
                new_tweets = [t for t in data.get('tweets', []) if t['id'] not in existing_tweet_ids]
                
                # åˆå¹¶
                existing_data['tweets'].extend(new_tweets)
                existing_data['collection_info']['tweets_count'] = len(existing_data['tweets'])
                existing_data['collection_info']['last_updated'] = datetime.now().isoformat()
                
                # ä¿å­˜åˆå¹¶åçš„æ•°æ®
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(existing_data, f, ensure_ascii=False, indent=2)
                
                print(f"ğŸ’¾ æ•°æ®has beenåˆå¹¶ä¿å­˜: {filepath}")
                print(f"   æ–°å¢æ¨æ–‡: {len(new_tweets)} entries")
                self.logger.info(f"Merged {len(new_tweets)} new tweets into {filename}")
            else:
                # ç›´æ¥ä¿å­˜æ–°File
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                
                print(f"ğŸ’¾ æ•°æ®has beenä¿å­˜: {filepath}")
                self.logger.info(f"Saved: {filename}")
        
        except Exception as e:
            self.logger.error(f"Failed to save {filename}: {e}")
            print(f"âŒ ä¿å­˜æ•°æ®Failed: {e}")
